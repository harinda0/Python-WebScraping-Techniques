{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e0f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c76245",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'amazon_book_beautifulsoup.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 149\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    148\u001b[0m     full_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Start timer for the full script\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     scrap_beautifulsoup()\n",
      "Cell \u001b[1;32mIn[5], line 61\u001b[0m, in \u001b[0;36mscrap_beautifulsoup\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(books_data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBook Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomers Rated\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     60\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamazon_book_beautifulsoup.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 61\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     63\u001b[0m scrape_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# End timer for scraping (including fetching page content)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScraping Time for BeautifulSoup (including fetching page content): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscrape_end_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mscrape_start_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'amazon_book_beautifulsoup.csv'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import NumeralTickFormatter\n",
    "\n",
    "# 1. Import Necessary Libraries\n",
    "# (Already done above)\n",
    "\n",
    "# 2. Scraping the Amazon Best Selling Books (100 Books)\n",
    "url_list = [\n",
    "    'https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_1',\n",
    "    'https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_2_books?ie=UTF8&pg=2'\n",
    "]\n",
    "\n",
    "# Function to scrape data using BeautifulSoup\n",
    "def scrap_beautifulsoup():\n",
    "    scrape_start_time = time.time()  # Start timer for scraping (including fetching page content)\n",
    "    books_data = []\n",
    "\n",
    "    for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Start timer for just scraping the data\n",
    "        data_scrape_start_time = time.time()\n",
    "\n",
    "        for book in soup.find_all('div', class_='p13n-sc-uncoverable-faceout'):\n",
    "            try:\n",
    "                book_name = book.find('div', class_='_cDEzb_p13n-sc-css-line-clamp-1_1Fn1y').text\n",
    "            except:\n",
    "                book_name = np.nan\n",
    "            try:\n",
    "                author = book.find('div', class_='a-row a-size-small').text\n",
    "            except:\n",
    "                author = np.nan\n",
    "            try:\n",
    "                rating = book.find('i').text\n",
    "            except:\n",
    "                rating = np.nan\n",
    "            try:\n",
    "                customer_rated = book.select_one('div.a-icon-row span.a-size-small').text\n",
    "            except:\n",
    "                customer_rated = np.nan\n",
    "            try:\n",
    "                price = book.find('span', class_='p13n-sc-price').text\n",
    "            except:\n",
    "                price = np.nan\n",
    "            books_data.append([book_name, author, rating, customer_rated, price])\n",
    "\n",
    "        # End timer for just scraping the data\n",
    "        data_scrape_end_time = time.time()\n",
    "\n",
    "    # 3. Using collected data create a CSV file (amazon_book_beautifulsoup.csv)\n",
    "    df = pd.DataFrame(books_data, columns=['Book Name', 'Author', 'Rating', 'Customers Rated', 'Price'])\n",
    "    file_name = 'amazon_book_beautifulsoup.csv'\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "    scrape_end_time = time.time()  # End timer for scraping (including fetching page content)\n",
    "    print(f'Scraping Time for BeautifulSoup (including fetching page content): {scrape_end_time - scrape_start_time} seconds')\n",
    "    print(f'Scraping Time for BeautifulSoup (just scraping the data): {data_scrape_end_time - data_scrape_start_time} seconds')\n",
    "\n",
    "    preprocess(file_name)\n",
    "    end_time = time.time()\n",
    "    print(f'Processing Time for BeautifulSoup (Full Script): {end_time - full_start_time} seconds')\n",
    "\n",
    "# 4. Reading the CSV File; and show the size, and head of the CSV file\n",
    "def preprocess(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print(data.shape)\n",
    "    print(data.head())\n",
    "\n",
    "    # 5. EDA on the collected CSV data:\n",
    "    # Pre-processing on the Rating, Customers Rated, and Price column.\n",
    "    # Example:\n",
    "    # Rating: should be a number only.\n",
    "    # Customers Rated: comma should be taken out and it should be an integer (how many customers rated this book)\n",
    "    # Price: comma and symbols should be taken out and it should also be a number\n",
    "\n",
    "    # Drop rows where both 'Price' and 'Rating' are NaN\n",
    "    data = data.dropna(subset=['Price', 'Rating'], how='all')\n",
    "\n",
    "    # Ensure 'Price' is treated as string before replacing and converting\n",
    "    data['Price'] = data['Price'].astype(str)\n",
    "\n",
    "    # Replace '₹' and ',' in 'Price', then convert to float\n",
    "    data['Price'] = data['Price'].str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "\n",
    "    # Convert 'Rating' to float\n",
    "    data['Rating'] = data['Rating'].str.extract(r'(\\d\\.\\d)').astype(float)\n",
    "\n",
    "    # Fill NaNs in 'Customers Rated' with 0 and convert to int\n",
    "    data['Customers Rated'] = data['Customers Rated'].str.replace(',', '').fillna('0').astype(int)\n",
    "\n",
    "    print(data.isna().sum())\n",
    "    print(data)\n",
    "\n",
    "    # 6. Check NaNs and take care of NaNs (May be drop the NaNs)\n",
    "    # (Already handled above by dropping rows where both 'Price' and 'Rating' are NaN)\n",
    "\n",
    "    # 7. List the Authors Highest Priced Book (i.e., based on price): show your result (at least top 25 highest priced book) as a data frame as well as a Bar diagram.\n",
    "    highest_priced_books = data.groupby('Author').agg({'Price': 'max'}).reset_index()\n",
    "    highest_priced_books = highest_priced_books.sort_values(by='Price', ascending=False).head(25)\n",
    "    print(highest_priced_books)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(highest_priced_books['Author'], highest_priced_books['Price'], color='skyblue')\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel('Author')\n",
    "    plt.title('Top 25 Highest Priced Books by Author')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    # 8. Show top Rated Books and Authors with respect to the highest customers rating (i.e., based on rating score): Show your result as a data frame as well as a Bar diagram.\n",
    "    top_rated_books = data.sort_values(by='Rating', ascending=False).head(25)\n",
    "    print(top_rated_books)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top_rated_books['Book Name'], top_rated_books['Rating'], color='green')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Book Name')\n",
    "    plt.title('Top 25 Rated Books')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    # 9. Show topmost (10/15) Customer Rated Authors and Books (i.e., based on number of customers): Show your result as a data frame as well as a bokeh.palettes, d3\n",
    "    # (https://docs.bokeh.org/en/latest/docs/reference/palettes.html)\n",
    "    top_customer_rated_books = data.sort_values(by='Customers Rated', ascending=False).head(15)\n",
    "    print(top_customer_rated_books)\n",
    "\n",
    "    output_file(\"top_customer_rated_books_beautifulsoup.html\")\n",
    "    p = figure(y_range=top_customer_rated_books['Book Name'], height=800, width=1200, title=\"Top 15 Customer Rated Books\",\n",
    "               toolbar_location=None, tools=\"\")\n",
    "    p.hbar(y=top_customer_rated_books['Book Name'], right=top_customer_rated_books['Customers Rated'], height=0.4, color=d3['Category20'][15])\n",
    "    p.xaxis.axis_label = \"Customers Rated\"\n",
    "    p.yaxis.axis_label = \"Book Name\"\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xaxis.formatter = NumeralTickFormatter(format=\"0,0\")\n",
    "\n",
    "    show(p)\n",
    "\n",
    "# 10. Complete the above tasks using at least three separate web scraping packages and compare their performance (processing time).\n",
    "if __name__ == \"__main__\":\n",
    "    full_start_time = time.time()  # Start timer for the full script\n",
    "    scrap_beautifulsoup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000f0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
